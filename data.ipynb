{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "import torch\n",
    "print(torch.version.cuda)\n",
    "print(torch.backends.cudnn.version())\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet50\n",
    "from multiprocessing import freeze_support\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "min_max_scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataSet(Dataset):\n",
    "    def __init__(self, root, image_size, transform=None):\n",
    "        self.images_path = []\n",
    "        self.images_class = []\n",
    "        target_folder = os.path.join(root, \"*.png\")\n",
    "        \n",
    "        for file_path in glob.glob(target_folder):\n",
    "            self.images_path.append(file_path)\n",
    "            image_name = os.path.basename(file_path)\n",
    "            first_part = image_name.split(\"_\")[0]\n",
    "            if(first_part == '0'):\n",
    "                self.images_class.append(0)\n",
    "            elif(first_part == '1'):\n",
    "                self.images_class.append(1)\n",
    "            elif(first_part == '2'):\n",
    "                self.images_class.append(2)\n",
    "            elif(first_part == '3'):\n",
    "                self.images_class.append(3)\n",
    "            elif(first_part == '4'):\n",
    "                self.images_class.append(4)\n",
    "            elif(first_part == '5'):\n",
    "                self.images_class.append(5)\n",
    "            elif(first_part == '6'):\n",
    "                self.images_class.append(6)\n",
    "            elif(first_part == '7'):\n",
    "                self.images_class.append(7)\n",
    "            elif(first_part == '8'):\n",
    "                self.images_class.append(8)\n",
    "            elif(first_part == '9'):\n",
    "                self.images_class.append(9)\n",
    "            else:\n",
    "                print(\"图片读取错误\")\n",
    "            \n",
    "            self.height_pd = pd.DataFrame(self.images_class)\n",
    "\n",
    "            self.height_pd.columns = ['label'] \n",
    "\n",
    "            \n",
    "            mean_height_list = [110.0, 133.0, 165.0, 175.0, 175.0, 176.0, 186.0, 160.0, 165.0, 163.0]  \n",
    "            def setting_height(row):\n",
    "                height = sorted(np.random.normal(mean_height_list[int(row)], 0.5,size=1))[0] \n",
    "                return np.round(height, 2)\n",
    "                # height = mean_height_list[int(row)]\n",
    "                # return height\n",
    "                \n",
    "            self.height_pd['height'] = self.height_pd['label'].apply(setting_height)\n",
    "            print(self.height_pd['height'])\n",
    "            # print('-------------------')\n",
    "            # print(self.height_pd.sample(5))\n",
    "            # print('-------------------')\n",
    "\n",
    "            min_max_scaler.fit(self.height_pd)\n",
    "            self.height = min_max_scaler.transform(self.height_pd)[:, 1]\n",
    "            self.height_label = min_max_scaler.transform(self.height_pd)[:, 0]  \n",
    "            \n",
    "            self.transform = transform\n",
    "            self.image_size = image_size\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        image = Image.open(self.images_path[index])\n",
    "        if image is None:\n",
    "            print(\"图像为空\")\n",
    "        label = self.height[index]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        transf = transforms.Compose([transforms.RandomRotation(degrees=15),\n",
    "                                     transforms.RandomResizedCrop(size=self.image_size, scale=(0.8, 1.0)),\n",
    "                                     transforms.ToTensor(),\n",
    "                                    #  transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "                                     ])\n",
    "        image =  transf(image)\n",
    "        label = torch.tensor(label)\n",
    "        return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path, batch_size, num_workers, train_ratio=0.7, val_ratio=0.2, image_size=224):\n",
    "    dataset = MyDataSet(data_path, image_size, transform=None)\n",
    "\n",
    "    num_data = len(dataset)\n",
    "    num_train = int(num_data * train_ratio)\n",
    "    num_val = int(num_data * val_ratio)\n",
    "    num_test = num_data - num_train - num_val\n",
    "\n",
    "    train_dataset, val_dataset, test_dataset = random_split(dataset, [num_train, num_val, num_test])\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, num_workers=num_workers)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "    return train_dataloader, val_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = load_data('/content/gdrive/MyDrive/fusion', 32, 4)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
